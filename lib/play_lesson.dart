// In order to make the text to speech on lessons possible, audio data must be retrieved
// from ElevenLabs AI using the getTtsAudioSource function
// There are two types of audio sources for the lessons: Lesson audio and Tts audio source

// Lesson audio sources only retrieve audio data from Firebase Storage
// TTS audio sources retrieve audio data generated by the TTS AI and returned by the API as
// an MPEG audio file, then handled by the just_audio package.

import 'dart:convert';

import 'package:e_dukaxon/main.dart';
import 'package:flutter/material.dart';
import 'package:just_audio/just_audio.dart';
import 'package:http/http.dart';

class PlayLesson {
  // This is an extra function that scrolls the page down after every text sentences are dictated
  void scrollPage(ScrollController scrollController, double scrollValue) {
    scrollController.animateTo(
      scrollController.offset + scrollValue,
      duration: const Duration(milliseconds: 500),
      curve: Curves.easeInOutCubic,
    );
  }

  Future<AudioSource> getLessonAudioSource(String url) async {
    try {
      return AudioSource.uri(Uri.parse(url));
    } catch (e) {
      print("Error: $e");
      // Returns an appropriate fallback source
      return AudioSource.uri(Uri.parse(''));
    }
  }

  //For the Text To Speech
  Future<AudioSource> getTtsAudioSource(String text) async {
    try {
      String voiceRachel = 'TX3LPaxmHKxFdv7VOQHJ';

      String url = 'https://api.elevenlabs.io/v1/text-to-speech/$voiceRachel';
      final response = await post(
        Uri.parse(url),
        headers: {
          'Accept': 'audio/mpeg',
          'xi-api-key': EL_API_KEY,
          'Content-Type': 'application/json',
        },
        body: json.encode({
          "text": text,
          "model_id": "eleven_multilingual_v2",
          "voice_settings": {"stability": 1, "similarity_boost": 0.5}
        }),
      );

      if (response.statusCode == 200) {
        final bytes = response.bodyBytes; //get the bytes ElevenLabs sent back
        return MyCustomSource(
            bytes); //send the bytes to be read from the JustAudio library
      } else {
        print('Failed to load audio');
        return AudioSource.uri(Uri.parse(''));
      }
    } catch (e) {
      print("Error: $e");
    }
    return AudioSource.uri(Uri.parse(''));
  }
}

// Feed the retrieved AI TTS audio bytes into the player
class MyCustomSource extends StreamAudioSource {
  final List<int> bytes;
  MyCustomSource(this.bytes);

  @override
  Future<StreamAudioResponse> request([int? start, int? end]) async {
    start ??= 0;
    end ??= bytes.length;
    return StreamAudioResponse(
      sourceLength: bytes.length,
      contentLength: end - start,
      offset: start,
      stream: Stream.value(bytes.sublist(start, end)),
      contentType: 'audio/mpeg',
    );
  }
}
